{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c98bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "openai.api_key = os.getenv("OPENAI_API_KEY")""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_processing_prompt(question, schema_doc):\n",
    "    \"\"\"\n",
    "    Function to generate prompts for GPT-based scoring\n",
    "    :param question: Question to the chatbot\n",
    "    :param schema_doc: Database Schema Document\n",
    "    :return: Prompt for the GPT model\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Your task is to analyze the provided question, identify the specific information being requested, and retrieve the relevant table and field(s) from the schema document to answer accurately. Always include EmployeeID and EmployeeName from the employee_fact_table to enable necessary joins. If the question references multiple tables, retrieve all applicable fields across tables and ensure to use the exact same table names as mentioned in the schema.\n",
    "    \n",
    "    Ensure the output is in the following JSON format. The output should strictly follow the JSON format and should not contain any additional information, comments, or suggestions.\n",
    "\n",
    "    If the requested information does not exist or cannot be found in the tables, set the `\"status\"` field to `\"not_found\"` and provide an appropriate message indicating that the information is not available.\n",
    "    \n",
    "    Example JSON format:\n",
    "    ```json\n",
    "    {{\n",
    "        \"status\": \"found\",\n",
    "        \"tables\": [\n",
    "            {{\n",
    "                \"table_name\": \"Employee Table\",\n",
    "                \"fields\": [\"EmployeeID\", \"EmployeeName\"]\n",
    "            }},\n",
    "            {{\n",
    "                \"table_name\": \"Project Table\",\n",
    "                \"fields\": [\"ProjectID\", \"EmployeeID\", \"ProjectDescription\", \"ProjectAllocationStartDate\", \"ProjectAllocationEndDate\"]\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    If the information is not found, the output should look like this:\n",
    "\n",
    "    {{\n",
    "    \"status\": \"not_found\",\n",
    "    \"message\": \"The requested information is not available, please ask your question again\"\n",
    "    }}\n",
    "    \n",
    "    Question:\n",
    "    {question}\n",
    "    \n",
    "    Schema Document:\n",
    "    {schema_doc}\n",
    "    \n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def question_answering_prompt(question, data_dict):\n",
    "    \"\"\"\n",
    "    Function to generate prompts for GPT based scoring\n",
    "    :param question: Question to the chatbot\n",
    "    :param employee_doc: Database Schema Document\n",
    "    :return: Prompt for the GPT model\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Your task is to help with an HR lookup where you are given a question about any relevant information contained in the provided tables. You need to analyze the question, identify the specific information being requested, and retrieve relevant details from the data uploaded to respond accurately.\n",
    "        \n",
    "    If the requested information does not exist or cannot be found in the tables, respond with an appropriate message indicating that the information is not available.\n",
    "    \n",
    "    Provide a worded, conversational response to the question, using the relevant information. The response should be phrased naturally, as if a chatbot is responding directly to the user. It should be clear, structured as full sentences, and flow smoothly. Avoid additional comments, suggestions, bullet points, or JSON formatting, and aim to answer in a friendly, informative style.\n",
    "    \n",
    "    Question:\n",
    "    {question}\n",
    "    \n",
    "    Data Dictionary:\n",
    "    {data_dict}\n",
    "    \n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def json_parser(gpt_output):\n",
    "    \"\"\"\n",
    "    Function to parse the JSON output from GPT model\n",
    "    :param gpt_output: JSON output from GPT model\n",
    "    :return: Parsed JSON output\n",
    "    \"\"\"\n",
    "    if gpt_output.startswith(\"```json\"):\n",
    "        gpt_output = gpt_output[7:]\n",
    "    if gpt_output.endswith(\"```\"):\n",
    "        gpt_output = gpt_output[:-3]\n",
    "\n",
    "    try:\n",
    "        parsed_output = json.loads(gpt_output.strip())\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSONDecodeError:\", e)\n",
    "        parsed_output = {}\n",
    "    \n",
    "    return parsed_output\n",
    "\n",
    "def question_processing_gpt4_output(question, schema_doc):\n",
    "    \"\"\"\n",
    "    Function to get the relevant fields from the  using GPT model\n",
    "    :param question: Resume text\n",
    "    :param schema_doc: Job description text\n",
    "    :return: Relevant Table and Fields Info\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = question_processing_prompt(question, schema_doc)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=512,\n",
    "        temperature=0\n",
    "    )\n",
    "    gpt_output = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    gpt_output = json_parser(gpt_output)\n",
    "    return gpt_output\n",
    "\n",
    "\n",
    "def question_answering_gpt4_output(question, data_dict):\n",
    "    \"\"\"\n",
    "    Function to get the relevant fields from the  using GPT model\n",
    "    :param question: Resume text\n",
    "    :param schema_doc: Job description text\n",
    "    :return: Relevant Table and Fields Info\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = question_answering_prompt(question, data_dict)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=512,\n",
    "        temperature=0\n",
    "    )\n",
    "    gpt_output = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return gpt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_fact_table = pd.read_csv('employee_fact_table.csv')\n",
    "progress_table_fact = pd.read_csv('progress_table.csv')\n",
    "project_table_dim = pd.read_csv('project_table.csv')\n",
    "\n",
    "def remove_spaces(df):\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    return df\n",
    "\n",
    "employee_fact_table = remove_spaces(employee_fact_table)\n",
    "progress_table_dim = remove_spaces(progress_table_fact)\n",
    "project_table_dim = remove_spaces(project_table_dim)\n",
    "\n",
    "progress_table = progress_table_dim.groupby('EmployeeID').agg(lambda x: list(x)).reset_index()\n",
    "project_table = project_table_dim.groupby('EmployeeID').agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "with open('database_schema.txt', 'r') as file:\n",
    "    schema_doc = file.read()\n",
    "\n",
    "while True:\n",
    "    question_text = input(\"Ask your question (or type 'stop' to end): \")\n",
    "    if question_text.lower() == 'stop':\n",
    "        break\n",
    "\n",
    "    table_dict = question_processing_gpt4_output(question_text, schema_doc)\n",
    "\n",
    "    if table_dict.get(\"status\") == \"found\":\n",
    "        result_df = None\n",
    "\n",
    "        for table in table_dict[\"tables\"]:\n",
    "            table_name = table[\"table_name\"]\n",
    "            fields = table[\"fields\"]\n",
    "\n",
    "            df_to_join = globals()[table_name][fields]\n",
    "\n",
    "            if result_df is None:\n",
    "                result_df = df_to_join\n",
    "            else:\n",
    "                result_df = pd.merge(\n",
    "                    result_df,\n",
    "                    df_to_join,\n",
    "                    on='EmployeeID',\n",
    "                    how='left'\n",
    "                )\n",
    "\n",
    "        df_json = result_df.to_json(orient=\"records\")\n",
    "        df_dict = json.loads(df_json)\n",
    "\n",
    "        answer = question_answering_gpt4_output(question_text, df_dict)\n",
    "        answer = answer.replace(\"\\\\n\", \"\\n\").replace(\"\\\\t\", \"\\t\").replace(\"\\\\'\", \"'\").replace('\\\\\"', '\"').replace(\"\\\\r\", \"\\r\").replace(\"\\''\", \"''\")\n",
    "        answer = ' '.join(answer.split())\n",
    "    else:\n",
    "        answer = table_dict.get(\"message\", \"The requested information is not available.\")\n",
    "\n",
    "    print(\"\\nResponse:\", answer, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe06bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf364a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
